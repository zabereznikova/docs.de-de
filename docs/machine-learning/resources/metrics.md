---
title: ML.NET-Metriken
description: Verstehen Sie die Metriken, die verwendet werden, um die Leistung eines ML.NET-Modells auszuwerten.
ms.date: 04/29/2019
author: natke
ms.openlocfilehash: 362f2f382d050ff9ae246af2dffe3e15d22452eb
ms.sourcegitcommit: 944ddc52b7f2632f30c668815f92b378efd38eea
ms.translationtype: HT
ms.contentlocale: de-DE
ms.lasthandoff: 11/03/2019
ms.locfileid: "73460732"
---
# <a name="model-evaluation-metrics-in-mlnet"></a><span data-ttu-id="705ac-103">Metriken für die Modellauswertung in ML.NET</span><span class="sxs-lookup"><span data-stu-id="705ac-103">Model evaluation metrics in ML.NET</span></span>

## <a name="metrics-for-binary-classification"></a><span data-ttu-id="705ac-104">Metriken für die binäre Klassifizierung</span><span class="sxs-lookup"><span data-stu-id="705ac-104">Metrics for Binary Classification</span></span>

| <span data-ttu-id="705ac-105">Metriken</span><span class="sxs-lookup"><span data-stu-id="705ac-105">Metrics</span></span>   |      <span data-ttu-id="705ac-106">BESCHREIBUNG</span><span class="sxs-lookup"><span data-stu-id="705ac-106">Description</span></span>      |  <span data-ttu-id="705ac-107">Suche nach</span><span class="sxs-lookup"><span data-stu-id="705ac-107">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="705ac-108">**Accuracy**</span><span class="sxs-lookup"><span data-stu-id="705ac-108">**Accuracy**</span></span> |  <span data-ttu-id="705ac-109">[Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) Dies ist der Anteil der korrekten Vorhersagen mit einem Testdataset.</span><span class="sxs-lookup"><span data-stu-id="705ac-109">[Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) is the proportion of correct predictions with a test data set.</span></span> <span data-ttu-id="705ac-110">Es ist das Verhältnis zwischen der Anzahl der korrekten Vorhersagen und der Gesamtzahl der Eingangsstichproben.</span><span class="sxs-lookup"><span data-stu-id="705ac-110">It is the ratio of number of correct predictions to the total number of input samples.</span></span> <span data-ttu-id="705ac-111">Es funktioniert nur dann gut, wenn es zu jeder Klasse eine ähnliche Anzahl von Stichproben gibt.</span><span class="sxs-lookup"><span data-stu-id="705ac-111">It works well only if there are similar number of samples belonging to each class.</span></span>| <span data-ttu-id="705ac-112">**Je näher der Wert an 1,00 liegt, desto besser**.</span><span class="sxs-lookup"><span data-stu-id="705ac-112">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="705ac-113">Aber ein Wert von genau 1,00 zeigt ein Problem an (häufig: Bezeichnung-Ziel-Verlust, Überanpassung oder Test mit Trainingsdaten).</span><span class="sxs-lookup"><span data-stu-id="705ac-113">But exactly 1.00 indicates an issue (commonly: label/target leakage, over-fitting, or testing with training data).</span></span> <span data-ttu-id="705ac-114">Wenn die Testdaten unausgewogen sind (wobei die meisten Instanzen zu einer der Klassen gehören), der Datensatz sehr klein ist oder die Werte auf 0,00 oder 1,00 ansteigen, dann wird die Effektivität eines Klassifikators nicht wirklich erfasst, und Sie müssen zusätzliche Metriken überprüfen.</span><span class="sxs-lookup"><span data-stu-id="705ac-114">When the test data is unbalanced (where most of the instances belong to one of the classes), the dataset is very small, or scores approach 0.00 or 1.00, then accuracy doesn’t really capture the effectiveness of a classifier and you need to check additional metrics.</span></span> |
| <span data-ttu-id="705ac-115">**AUC**</span><span class="sxs-lookup"><span data-stu-id="705ac-115">**AUC**</span></span> |    <span data-ttu-id="705ac-116">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) oder *Area under the curve* (Fläche unter der Kurve): Dies ist die Messung der Fläche unter der Kurve, die durch das Aufräumen der richtigen Positivfälle gegenüber den falsch Positivfällen erzeugt wird.</span><span class="sxs-lookup"><span data-stu-id="705ac-116">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) or *Area under the curve*: This is measuring the area under the curve created by sweeping the true positive rate vs. the false positive rate.</span></span>  |   <span data-ttu-id="705ac-117">**Je näher der Wert an 1,00 liegt, desto besser**.</span><span class="sxs-lookup"><span data-stu-id="705ac-117">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="705ac-118">Der Wert sollte größer als 0,50 sein, damit ein Modell akzeptabel ist; ein Modell mit einem AUC-Wert von 0,50 oder weniger ist wertlos.</span><span class="sxs-lookup"><span data-stu-id="705ac-118">It should be greater than 0.50 for a model to be acceptable; a model with AUC of 0.50 or less is worthless.</span></span> |
| <span data-ttu-id="705ac-119">**aucPR**</span><span class="sxs-lookup"><span data-stu-id="705ac-119">**AUCPR**</span></span> | <span data-ttu-id="705ac-120">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) oder *Area under a Precision-Recall curve* (Fläche unter der Precision-Recall-Kurve): Nützliches Maß für den Erfolg der Vorhersage, wenn die Klassen sehr unausgewogen sind (stark verzerrte Datasets).</span><span class="sxs-lookup"><span data-stu-id="705ac-120">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) or *Area under the curve of a Precision-Recall curve*: Useful measure of success of prediction when the classes are very imbalanced (highly skewed datasets).</span></span> |  <span data-ttu-id="705ac-121">**Je näher der Wert an 1,00 liegt, desto besser**.</span><span class="sxs-lookup"><span data-stu-id="705ac-121">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="705ac-122">Hohe Werte nahe 1,00 zeigen, dass der Klassifikator sowohl genaue Ergebnisse liefert (hohe Präzision) als auch einen Großteil aller positiven Ergebnisse liefert (hohe Wiedererkennung).</span><span class="sxs-lookup"><span data-stu-id="705ac-122">High scores close to 1.00 show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).</span></span> |
| <span data-ttu-id="705ac-123">**F1-score**</span><span class="sxs-lookup"><span data-stu-id="705ac-123">**F1-score**</span></span> | <span data-ttu-id="705ac-124">[F1-score](https://en.wikipedia.org/wiki/F1_score) auch bezeichnet als *„balanced F-score“ oder F-Maß*.</span><span class="sxs-lookup"><span data-stu-id="705ac-124">[F1 score](https://en.wikipedia.org/wiki/F1_score) also known as *balanced F-score or F-measure*.</span></span> <span data-ttu-id="705ac-125">Dies ist das harmonische Mittel zwischen Präzision und Wiedererkennung.</span><span class="sxs-lookup"><span data-stu-id="705ac-125">It's the harmonic mean of the precision and recall.</span></span> <span data-ttu-id="705ac-126">F1 Score ist hilfreich, wenn das Verhältnis zwischen Präzision und Wiedererkennung ausgeglichen sein soll.</span><span class="sxs-lookup"><span data-stu-id="705ac-126">F1 Score is helpful when you want to seek a balance between Precision and Recall.</span></span>| <span data-ttu-id="705ac-127">**Je näher der Wert an 1,00 liegt, desto besser**.</span><span class="sxs-lookup"><span data-stu-id="705ac-127">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="705ac-128">Ein F1-Score erreicht seinen besten Wert bei 1,00 und den schlechtesten bei 0,00.</span><span class="sxs-lookup"><span data-stu-id="705ac-128">An F1 score reaches its best value at 1.00 and worst score at 0.00.</span></span> <span data-ttu-id="705ac-129">Daran erkennen Sie, wie präzise Ihr Klassifizierer ist.</span><span class="sxs-lookup"><span data-stu-id="705ac-129">It tells you how precise your classifier is.</span></span> |

<span data-ttu-id="705ac-130">Weitere Informationen zu binären Klassifizierungsmetriken finden Sie in den folgenden Artikeln:</span><span class="sxs-lookup"><span data-stu-id="705ac-130">For further details on binary classification metrics read the following articles:</span></span>

- <span data-ttu-id="705ac-131">[Accuracy, Precision, Recall or F1?](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9) (Genauigkeit, Präzision, Wiedererkennung oder F1?)</span><span class="sxs-lookup"><span data-stu-id="705ac-131">[Accuracy, Precision, Recall or F1?](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)</span></span>
- <span data-ttu-id="705ac-132">[Binary Classification Metrics class](xref:Microsoft.ML.Data.BinaryClassificationMetrics) (Metrikklassen für die binäre Klassifizierung)</span><span class="sxs-lookup"><span data-stu-id="705ac-132">[Binary Classification Metrics class](xref:Microsoft.ML.Data.BinaryClassificationMetrics)</span></span>
- <span data-ttu-id="705ac-133">[The Relationship Between Precision-Recall and ROC Curves](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf) (Das Verhältnis zwischen Precision-Recall- und ROC-Kurven)</span><span class="sxs-lookup"><span data-stu-id="705ac-133">[The Relationship Between Precision-Recall and ROC Curves](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf)</span></span>

## <a name="metrics-for-multi-class-classification"></a><span data-ttu-id="705ac-134">Metriken für Multiklassen-Klassifizierungsmodelle</span><span class="sxs-lookup"><span data-stu-id="705ac-134">Metrics for Multi-class Classification</span></span>

| <span data-ttu-id="705ac-135">Metriken</span><span class="sxs-lookup"><span data-stu-id="705ac-135">Metrics</span></span>   |      <span data-ttu-id="705ac-136">BESCHREIBUNG</span><span class="sxs-lookup"><span data-stu-id="705ac-136">Description</span></span>      |  <span data-ttu-id="705ac-137">Suche nach</span><span class="sxs-lookup"><span data-stu-id="705ac-137">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="705ac-138">**Micro-Accuracy**</span><span class="sxs-lookup"><span data-stu-id="705ac-138">**Micro-Accuracy**</span></span> |  <span data-ttu-id="705ac-139">Die [durchschnittliche Mikrogenauigkeit](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) aggregiert die Beiträge aller Klassen zur Berechnung der durchschnittlichen Metrik.</span><span class="sxs-lookup"><span data-stu-id="705ac-139">[Micro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) aggregates the contributions of all classes to compute the average metric.</span></span> <span data-ttu-id="705ac-140">Es ist der Anteil der korrekt vorhergesagten Instanzen.</span><span class="sxs-lookup"><span data-stu-id="705ac-140">It is the fraction of instances predicted correctly.</span></span> <span data-ttu-id="705ac-141">Der Mikrodurchschnitt berücksichtigt nicht die Klassenzugehörigkeit.</span><span class="sxs-lookup"><span data-stu-id="705ac-141">The micro-average does not take class membership into account.</span></span> <span data-ttu-id="705ac-142">Jedes Beispiel/Klasse-Paar trägt grundsätzlich zu gleichen Teilen zur Genauigkeitsmetrik bei.</span><span class="sxs-lookup"><span data-stu-id="705ac-142">Basically, every sample-class pair contributes equally to the accuracy metric.</span></span> | <span data-ttu-id="705ac-143">**Je näher der Wert an 1,00 liegt, desto besser**.</span><span class="sxs-lookup"><span data-stu-id="705ac-143">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="705ac-144">In einer Aufgabe für die Multiklassenklassifizierung ist die Mikrogenauigkeit der Makrogenauigkeit vorzuziehen, wenn Sie vermuten, dass es ein Klassenungleichgewicht geben könnte (d.h.</span><span class="sxs-lookup"><span data-stu-id="705ac-144">In a multi-class classification task, micro-accuracy is preferable over macro-accuracy if you suspect there might be class imbalance (i.e</span></span> <span data-ttu-id="705ac-145">Sie haben viel mehr Beispiele für eine Klasse als für andere Klassen).</span><span class="sxs-lookup"><span data-stu-id="705ac-145">you may have many more examples of one class than of other classes).</span></span>|
| <span data-ttu-id="705ac-146">**Macro-Accuracy**</span><span class="sxs-lookup"><span data-stu-id="705ac-146">**Macro-Accuracy**</span></span> | <span data-ttu-id="705ac-147">Die [durchschnittliche Makrogenauigkeit](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) ist die durchschnittliche Genauigkeit auf Klassenebene.</span><span class="sxs-lookup"><span data-stu-id="705ac-147">[Macro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) is the average accuracy at the class level.</span></span> <span data-ttu-id="705ac-148">Die Genauigkeit für jede Klasse wird berechnet, und die Makrogenauigkeit ist der Durchschnitt dieser Genauigkeiten.</span><span class="sxs-lookup"><span data-stu-id="705ac-148">The accuracy for each class is computed and the macro-accuracy is the average of these accuracies.</span></span> <span data-ttu-id="705ac-149">Grundsätzlich trägt jede Klasse zu gleichen Teilen zur Genauigkeitsmetrik bei.</span><span class="sxs-lookup"><span data-stu-id="705ac-149">Basically, every class contributes equally to the accuracy metric.</span></span> <span data-ttu-id="705ac-150">Minderheitsklassen werden gleich wie größere Klassen gewichtet.</span><span class="sxs-lookup"><span data-stu-id="705ac-150">Minority classes are given equal weight as the larger classes.</span></span> <span data-ttu-id="705ac-151">Die Metrik gibt jeder Klasse die gleiche Gewichtung, unabhängig davon, wie viele Instanzen aus dieser Klasse das Dataset enthält.</span><span class="sxs-lookup"><span data-stu-id="705ac-151">The macro-average metric gives the same weight to each class, no matter how many instances from that class the dataset contains.</span></span> |  <span data-ttu-id="705ac-152">**Je näher der Wert an 1,00 liegt, desto besser**.</span><span class="sxs-lookup"><span data-stu-id="705ac-152">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="705ac-153">Sie berechnet die Metrik unabhängig für jede Klasse und ermittelt dann den Durchschnitt (daher werden alle Klassen gleich behandelt).</span><span class="sxs-lookup"><span data-stu-id="705ac-153">It computes the metric independently for each class and then takes the average (hence treating all classes equally)</span></span> |
| <span data-ttu-id="705ac-154">**Log-loss**</span><span class="sxs-lookup"><span data-stu-id="705ac-154">**Log-loss**</span></span>| <span data-ttu-id="705ac-155">Der [logarithmische Verlust](http://wiki.fast.ai/index.php/Log_Loss) misst die Leistung eines Klassifizierungsmodells, wobei die Vorhersageeingabe ein Wahrscheinlichkeitswert zwischen 0,00 und 1,00 ist.</span><span class="sxs-lookup"><span data-stu-id="705ac-155">[Logarithmic loss](http://wiki.fast.ai/index.php/Log_Loss) measures the performance of a classification model where the prediction input is a probability value between 0.00 and 1.00.</span></span> <span data-ttu-id="705ac-156">Der Wert steigt, wenn die vorhergesagte Wahrscheinlichkeit von der tatsächlichen Bezeichnung abweicht.</span><span class="sxs-lookup"><span data-stu-id="705ac-156">Log-loss increases as the predicted probability diverges from the actual label.</span></span> | <span data-ttu-id="705ac-157">**Je näher der Wert an 0,00 liegt, desto besser**.</span><span class="sxs-lookup"><span data-stu-id="705ac-157">**The closer to 0.00, the better**.</span></span> <span data-ttu-id="705ac-158">Bei einem perfekten Modell liegt der Wert bei 0,00.</span><span class="sxs-lookup"><span data-stu-id="705ac-158">A perfect model would have a log-loss of 0.00.</span></span> <span data-ttu-id="705ac-159">Ziel unserer Machine Learning-Modelle ist es, diesen Wert zu minimieren.</span><span class="sxs-lookup"><span data-stu-id="705ac-159">The goal of our machine learning models is to minimize this value.</span></span>|
| <span data-ttu-id="705ac-160">**Log-Loss Reduction**</span><span class="sxs-lookup"><span data-stu-id="705ac-160">**Log-Loss Reduction**</span></span> | <span data-ttu-id="705ac-161">Die [logarithmische Verlustreduzierung](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) kann als Vorteil des Klassifizierers gegenüber einer Zufallsvorhersage interpretiert werden.</span><span class="sxs-lookup"><span data-stu-id="705ac-161">[Logarithmic loss reduction](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) can be interpreted as the advantage of the classifier over a random prediction.</span></span>| <span data-ttu-id="705ac-162">**Liegt zwischen [-inf, 1.00], wobei „1.00“ perfekte Vorhersagen und „0.00“ durchschnittliche Vorhersagen bedeutet.**</span><span class="sxs-lookup"><span data-stu-id="705ac-162">**Ranges from -inf and 1.00, where 1.00 is perfect predictions and 0.00 indicates mean predictions**.</span></span> <span data-ttu-id="705ac-163">Wenn der Wert beispielsweise 0,20 beträgt, kann er als „die Wahrscheinlichkeit einer korrekten Vorhersage ist 20 % besser als eine zufällige Schätzung“ interpretiert werden.</span><span class="sxs-lookup"><span data-stu-id="705ac-163">For example, if the value equals 0.20, it can be interpreted as "the probability of a correct prediction is 20% better than random guessing"</span></span>|

<span data-ttu-id="705ac-164">Die Mikrogenauigkeit ist im Allgemeinen besser auf die Geschäftsanforderungen der ML-Vorhersagen ausgerichtet.</span><span class="sxs-lookup"><span data-stu-id="705ac-164">Micro-accuracy is generally better aligned with the business needs of ML predictions.</span></span> <span data-ttu-id="705ac-165">Wenn Sie eine einzelne Metrik für die Auswahl der Qualität einer Aufgabe für die Multiklassenklassifizierung auswählen, sollte dies in der Regel die Mikrogenauigkeit sein.</span><span class="sxs-lookup"><span data-stu-id="705ac-165">If you want to select a single metric for choosing the quality of a multiclass classification task, it should usually be micro-accuracy.</span></span>

<span data-ttu-id="705ac-166">Beispiel für eine Aufgabe zur Klassifizierung von Supporttickets: (ordnet eingehende Tickets den Support-Teams zu)</span><span class="sxs-lookup"><span data-stu-id="705ac-166">Example, for a support ticket classification task: (maps incoming tickets to support teams)</span></span>

- <span data-ttu-id="705ac-167">Mikrogenauigkeit – wie oft wird ein eingehendes Ticket dem richtigen Team zugeordnet?</span><span class="sxs-lookup"><span data-stu-id="705ac-167">Micro-accuracy -- how often does an incoming ticket get classified to the right team?</span></span>
- <span data-ttu-id="705ac-168">Makrogenauigkeit für dein durchschnittliches Team – wie oft ist ein eingehendes Ticket das richtige Ticket für das Team?</span><span class="sxs-lookup"><span data-stu-id="705ac-168">Macro-accuracy -- for an average team, how often is an incoming ticket correct for their team?</span></span>

<span data-ttu-id="705ac-169">Die Makrogenauigkeit gewichtet in diesem Beispiel kleine Teams zu hoch; ein kleines Team, das nur 10 Tickets pro Jahr erhält, zählt ebenso viel wie ein großes Team mit 10k Tickets pro Jahr.</span><span class="sxs-lookup"><span data-stu-id="705ac-169">Macro-accuracy overweights small teams in this example; a small team which gets only 10 tickets per year counts as much as a large team with 10k tickets per year.</span></span> <span data-ttu-id="705ac-170">Die Mikrogenauigkeit korreliert in diesem Fall besser mit der Geschäftsanforderung: „Wie viel Zeit/Geld kann das Unternehmen durch die Automatisierung meines Prozesses für die Ticketweiterleitung sparen“.</span><span class="sxs-lookup"><span data-stu-id="705ac-170">Micro-accuracy in this case correlates better with the business need of, "how much time/money can the company save by automating my ticket routing process".</span></span>

<span data-ttu-id="705ac-171">Weitere Informationen zu Metriken für die Multiklassenklassifizierung finden Sie in den folgenden Artikeln:</span><span class="sxs-lookup"><span data-stu-id="705ac-171">For further details on multi-class classification metrics read the following articles:</span></span>

- <span data-ttu-id="705ac-172">[Micro- and Macro-average of Precision, Recall and F-Score](https://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html) (Mikro- und Makrodurchschnitt von Präzision, Wiedererkennung und F-Score)</span><span class="sxs-lookup"><span data-stu-id="705ac-172">[Micro- and Macro-average of Precision, Recall and F-Score](https://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html)</span></span>
- <span data-ttu-id="705ac-173">[Multiclass Classification with Imbalanced Dataset](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a) (Multiklassenklassifizierung mit unausgeglichenen Datasets)</span><span class="sxs-lookup"><span data-stu-id="705ac-173">[Multiclass Classification with Imbalanced Dataset](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a)</span></span>

## <a name="metrics-for-regression"></a><span data-ttu-id="705ac-174">Metriken für Regression</span><span class="sxs-lookup"><span data-stu-id="705ac-174">Metrics for Regression</span></span>

| <span data-ttu-id="705ac-175">Metriken</span><span class="sxs-lookup"><span data-stu-id="705ac-175">Metrics</span></span>   |      <span data-ttu-id="705ac-176">BESCHREIBUNG</span><span class="sxs-lookup"><span data-stu-id="705ac-176">Description</span></span>      |  <span data-ttu-id="705ac-177">Suche nach</span><span class="sxs-lookup"><span data-stu-id="705ac-177">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="705ac-178">**R-squared**</span><span class="sxs-lookup"><span data-stu-id="705ac-178">**R-Squared**</span></span> |  <span data-ttu-id="705ac-179">[R-squared (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination) oder *Bestimmtheitsmaß* stellt die Vorhersageleistung des Modells als Wert zwischen -inf und 1,00 dar.</span><span class="sxs-lookup"><span data-stu-id="705ac-179">[R-squared (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), or *Coefficient of determination* represents the predictive power of the model as a value between -inf and 1.00.</span></span> <span data-ttu-id="705ac-180">1,00 bedeutet, dass das Modell perfekt geeignet ist. Die Eignung kann aber auch willkürlich schlecht sein, sodass die Werte negativ sein können.</span><span class="sxs-lookup"><span data-stu-id="705ac-180">1.00 means there is a perfect fit, and the fit can be arbitrarily poor so the scores can be negative.</span></span> <span data-ttu-id="705ac-181">Ein Score von 0,00 bedeutet, dass das Modell den erwarteten Wert für die Bezeichnung schätzt.</span><span class="sxs-lookup"><span data-stu-id="705ac-181">A score of 0.00 means the model is guessing the expected value for the label.</span></span> <span data-ttu-id="705ac-182">R2 misst, wie nah die tatsächlichen Testdatenwerte an den vorhergesagten Werten liegen.</span><span class="sxs-lookup"><span data-stu-id="705ac-182">R2 measures how close the actual test data values are to the predicted values.</span></span> | <span data-ttu-id="705ac-183">**Je näher der Wert an 1,00 liegt, desto besser ist die Qualität des Modells**.</span><span class="sxs-lookup"><span data-stu-id="705ac-183">**The closer to 1.00, the better quality**.</span></span> <span data-ttu-id="705ac-184">Manchmal können jedoch niedrige R-squared-Werte (z.B. 0,50) ganz normal oder gut genug für Ihr Szenario sein, und hohe R-squared-Werte sind nicht immer gut und möglicherweise verdächtig.</span><span class="sxs-lookup"><span data-stu-id="705ac-184">However, sometimes low R-squared values (such as 0.50) can be entirely normal or good enough for your scenario and high R-squared values are not always good and be suspicious.</span></span> |
| <span data-ttu-id="705ac-185">**Absolute-loss**</span><span class="sxs-lookup"><span data-stu-id="705ac-185">**Absolute-loss**</span></span> |  <span data-ttu-id="705ac-186">[Absolute-loss](https://en.wikipedia.org/wiki/Mean_absolute_error) oder *Mittlerer absoluter Fehler (MAE)* misst, wie nah die Vorhersagen an den tatsächlichen Ergebnissen liegen.</span><span class="sxs-lookup"><span data-stu-id="705ac-186">[Absolute-loss](https://en.wikipedia.org/wiki/Mean_absolute_error) or *Mean absolute error (MAE)* measures how close the predictions are to the actual outcomes.</span></span> <span data-ttu-id="705ac-187">Damit wird der Durchschnitt aller Modellfehler angegeben, wobei ein Modellfehler die Differenz zwischen dem vorhergesagten Wert für die Bezeichnung und dem korrekten Wert für die Bezeichnung ist.</span><span class="sxs-lookup"><span data-stu-id="705ac-187">It is the average of all the model errors, where model error is the absolute distance between the predicted label value and the correct label value.</span></span> <span data-ttu-id="705ac-188">Dieser Vorhersagefehler wird für jeden Datensatz des Testdatasets berechnet.</span><span class="sxs-lookup"><span data-stu-id="705ac-188">This prediction error is calculated for each record of the test data set.</span></span> <span data-ttu-id="705ac-189">Abschließend wird der Mittelwert für alle erfassten absoluten Fehler berechnet.</span><span class="sxs-lookup"><span data-stu-id="705ac-189">Finally, the mean value is calculated for all recorded absolute errors.</span></span>| <span data-ttu-id="705ac-190">**Je näher der Wert an 0,00 liegt, desto besser ist die Qualität des Modells**.</span><span class="sxs-lookup"><span data-stu-id="705ac-190">**The closer to 0.00, the better quality.**</span></span> <span data-ttu-id="705ac-191">Beachten Sie, dass der mittlere absolute Fehler die gleiche Staffelung wie die zu messenden Daten verwendet (ist nicht auf einen bestimmten Bereich normiert).</span><span class="sxs-lookup"><span data-stu-id="705ac-191">Note that the mean absolute error uses the same scale as the data being measured (is not normalized to specific range).</span></span> <span data-ttu-id="705ac-192">„Absolute-loss“, „Squared-loss“ und „RMS-loss“ können nur zum Vergleich von Modellen für dasselbe Dataset oder Datasets mit einer ähnlichen Bezeichnung-Wert-Verteilung verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="705ac-192">Absolute-loss, Squared-loss, and RMS-loss can only be used to make comparisons between models for the same dataset or dataset with a similar label value distribution.</span></span> |
| <span data-ttu-id="705ac-193">**Squared-loss**</span><span class="sxs-lookup"><span data-stu-id="705ac-193">**Squared-loss**</span></span> |  <span data-ttu-id="705ac-194">[Squared-loss](https://en.wikipedia.org/wiki/Mean_squared_error) oder *Mittlerer quadratischer Fehler (Mean Squared Error, MSE)* , auch als  *Mittlere quadratische Abweichung (Mean Squared Deviation, MSD)* bezeichnet, gibt an, wie nah die Regressionsgerade an einem Satz an Testdatenwerten liegt.</span><span class="sxs-lookup"><span data-stu-id="705ac-194">[Squared-loss](https://en.wikipedia.org/wiki/Mean_squared_error) or *Mean Squared Error (MSE)*, also called *Mean Squared Deviation (MSD)*, tells you how close a regression line is to a set of test data values.</span></span> <span data-ttu-id="705ac-195">Dazu werden die Abstände von den Punkten zur Regressionsgeraden (diese Abstände sind die „Fehler“) herangezogen und quadriert.</span><span class="sxs-lookup"><span data-stu-id="705ac-195">It does this by taking the distances from the points to the regression line (these distances are the errors E) and squaring them.</span></span> <span data-ttu-id="705ac-196">Durch das Quadrieren wird größeren Unterschieden eine höhere Gewichtung zugewiesen.</span><span class="sxs-lookup"><span data-stu-id="705ac-196">The squaring gives more weight to larger differences.</span></span> | <span data-ttu-id="705ac-197">Der Wert ist immer nicht negativ, und **Werte, die näher an 0,00 liegen, sind besser**.</span><span class="sxs-lookup"><span data-stu-id="705ac-197">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="705ac-198">In Abhängigkeit von Ihren Daten kann es unmöglich sein, für den mittleren quadratischen Fehler einen sehr kleinen Wert zu erhalten.</span><span class="sxs-lookup"><span data-stu-id="705ac-198">Depending on your data, it may be impossible to get a very small value for the mean squared error.</span></span>|
| <span data-ttu-id="705ac-199">**RMS-loss**</span><span class="sxs-lookup"><span data-stu-id="705ac-199">**RMS-loss**</span></span> |  <span data-ttu-id="705ac-200">[RMS-loss](https://en.wikipedia.org/wiki/Root-mean-square_deviation) oder *Wurzel aus dem mittleren quadratischen Fehler (Root Mean Squared Error, RMSE)* (auch als *Wurzel aus der mittleren quadratischen Abweichung [Root Mean Square Deviation, RMSD*]), misst die Differenz zwischen den von einem Modell vorhergesagten Werten und den tatsächlich beobachteten Werten aus der zu modellierenden Umgebung.</span><span class="sxs-lookup"><span data-stu-id="705ac-200">[RMS-loss](https://en.wikipedia.org/wiki/Root-mean-square_deviation) or *Root Mean Squared Error (RMSE)* (also called *Root Mean Square Deviation, RMSD*), measures the difference between values predicted by a model and the values actually observed from the environment that is being modeled.</span></span> <span data-ttu-id="705ac-201">„RMS-loss“ ist die Quadratwurzel von „Squared-loss“ und verwendet, ähnlich wie „Absolute-loss“ dieselben Einheiten wie die Bezeichnung, weist jedoch größeren Unterschieden mehr Gewichtung zu.</span><span class="sxs-lookup"><span data-stu-id="705ac-201">RMS-loss is the square root of Squared-loss and has the same units as the label, similar to the absolute-loss though giving more weight to larger differences.</span></span> <span data-ttu-id="705ac-202">Die Wurzel aus dem mittleren quadratischen Fehler wird häufig in der Klimatologie, für Vorhersagen und Regressionsanalyse verwendet, um experimentelle Ergebnisse zu überprüfen.</span><span class="sxs-lookup"><span data-stu-id="705ac-202">Root mean square error is commonly used in climatology, forecasting, and regression analysis to verify experimental results.</span></span> | <span data-ttu-id="705ac-203">Der Wert ist immer nicht negativ, und **Werte, die näher an 0,00 liegen, sind besser**.</span><span class="sxs-lookup"><span data-stu-id="705ac-203">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="705ac-204">RMSD ist ein Maß für die Genauigkeit, um Vorhersagefehler verschiedener Modelle für ein bestimmtes Dataset zu vergleichen und nicht für verschiedene Datasets, da der Wert staffelungsabhängig ist.</span><span class="sxs-lookup"><span data-stu-id="705ac-204">RMSD is a measure of accuracy, to compare forecasting errors of different models for a particular dataset and not between datasets, as it is scale-dependent.</span></span>|

<span data-ttu-id="705ac-205">Weitere Informationen zu Regressionsmetriken finden Sie in den folgenden Artikeln:</span><span class="sxs-lookup"><span data-stu-id="705ac-205">For further details on regression metrics, read the following articles:</span></span>

- <span data-ttu-id="705ac-206">[Regression Analysis: How Do I Interpret R-squared and Assess the Goodness-of-Fit?](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit) (Regressionsanalyse: Interpretieren von „R-squared“ und Bewerten der Anpassungsgüte)</span><span class="sxs-lookup"><span data-stu-id="705ac-206">[Regression Analysis: How Do I Interpret R-squared and Assess the Goodness-of-Fit?](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)</span></span>
- <span data-ttu-id="705ac-207">[How To Interpret R-squared in Regression Analysis](https://statisticsbyjim.com/regression/interpret-r-squared-regression) (Interpretieren von „R-squared“ in der Regressionsanalyse)</span><span class="sxs-lookup"><span data-stu-id="705ac-207">[How To Interpret R-squared in Regression Analysis](https://statisticsbyjim.com/regression/interpret-r-squared-regression)</span></span>
- <span data-ttu-id="705ac-208">[R-Squared Definition](https://www.investopedia.com/terms/r/r-squared.asp) (R-Squared-Definition)</span><span class="sxs-lookup"><span data-stu-id="705ac-208">[R-Squared Definition](https://www.investopedia.com/terms/r/r-squared.asp)</span></span>
- <span data-ttu-id="705ac-209">[Mean Squared Error Definition](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/) (Definition des mittleren quadratischen Fehlers)</span><span class="sxs-lookup"><span data-stu-id="705ac-209">[Mean Squared Error Definition](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/)</span></span>
- <span data-ttu-id="705ac-210">[What are Mean Squared Error and Root Mean Squared Error?](https://www.vernier.com/til/1014/) (Was sind der mittlere quadratische Fehler und die Wurzel aus dem mittleren quadratischen Fehler?)</span><span class="sxs-lookup"><span data-stu-id="705ac-210">[What are Mean Squared Error and Root Mean Squared Error?](https://www.vernier.com/til/1014/)</span></span>
