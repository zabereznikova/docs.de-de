---
title: ML.NET-Metriken
description: Verstehen Sie die Metriken, die verwendet werden, um die Leistung eines ML.NET-Modells auszuwerten.
ms.date: 12/17/2019
ms.openlocfilehash: 4aca8dbdd9f137509ab9167ecc77f9ca6994e415
ms.sourcegitcommit: aa6d8a90a4f5d8fe0f6e967980b8c98433f05a44
ms.translationtype: HT
ms.contentlocale: de-DE
ms.lasthandoff: 09/16/2020
ms.locfileid: "90679507"
---
# <a name="evaluate-your-mlnet-model-with-metrics"></a><span data-ttu-id="6b374-103">Auswerten des ML.NET-Modells mit Metriken</span><span class="sxs-lookup"><span data-stu-id="6b374-103">Evaluate your ML.NET model with metrics</span></span>

<span data-ttu-id="6b374-104">Verstehen der Metriken, die zum Auswerten eines ML.NET-Modells verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="6b374-104">Understand the metrics used to evaluate an ML.NET model.</span></span>

<span data-ttu-id="6b374-105">Auswertungsmetriken sind spezifisch für den Typ der Machine Learning-Aufgabe, die ein Modell ausführt.</span><span class="sxs-lookup"><span data-stu-id="6b374-105">Evaluation metrics are specific to the type of machine learning task that a model performs.</span></span>

<span data-ttu-id="6b374-106">Beispielsweise wird für die Klassifizierungsaufgabe das Modell ausgewertet, indem gemessen wird, wie gut eine vorhergesagte Kategorie mit der tatsächlichen Kategorie übereinstimmt.</span><span class="sxs-lookup"><span data-stu-id="6b374-106">For example, for the classification task, the model is evaluated by measuring how well a predicted category matches the actual category.</span></span> <span data-ttu-id="6b374-107">Bei Clustering basiert die Auswertung darauf, wie nahe die gruppierten Elemente beieinander liegen und wie viel Trennung zwischen den Clustern vorhanden ist.</span><span class="sxs-lookup"><span data-stu-id="6b374-107">And for clustering, evaluation is based on how close clustered items are to each other, and how much separation there is between the clusters.</span></span>

## <a name="evaluation-metrics-for-binary-classification"></a><span data-ttu-id="6b374-108">Auswertungsmetriken für binäre Klassifizierung</span><span class="sxs-lookup"><span data-stu-id="6b374-108">Evaluation metrics for Binary Classification</span></span>

| <span data-ttu-id="6b374-109">Metriken</span><span class="sxs-lookup"><span data-stu-id="6b374-109">Metrics</span></span>   |      <span data-ttu-id="6b374-110">BESCHREIBUNG</span><span class="sxs-lookup"><span data-stu-id="6b374-110">Description</span></span>      |  <span data-ttu-id="6b374-111">Suchen nach</span><span class="sxs-lookup"><span data-stu-id="6b374-111">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="6b374-112">**Genauigkeit**</span><span class="sxs-lookup"><span data-stu-id="6b374-112">**Accuracy**</span></span> |  <span data-ttu-id="6b374-113">[Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) Dies ist der Anteil der korrekten Vorhersagen mit einem Testdataset.</span><span class="sxs-lookup"><span data-stu-id="6b374-113">[Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) is the proportion of correct predictions with a test data set.</span></span> <span data-ttu-id="6b374-114">Es ist das Verhältnis zwischen der Anzahl der korrekten Vorhersagen und der Gesamtzahl der Eingangsstichproben.</span><span class="sxs-lookup"><span data-stu-id="6b374-114">It is the ratio of number of correct predictions to the total number of input samples.</span></span> <span data-ttu-id="6b374-115">Dies funktioniert gut, wenn es zu jeder Klasse eine ähnliche Anzahl von Stichproben gibt.</span><span class="sxs-lookup"><span data-stu-id="6b374-115">It works well if there are similar number of samples belonging to each class.</span></span>| <span data-ttu-id="6b374-116">**Je näher der Wert an 1,00 liegt, desto besser**.</span><span class="sxs-lookup"><span data-stu-id="6b374-116">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="6b374-117">Aber ein Wert von genau 1,00 zeigt ein Problem an (häufig: Bezeichnung-Ziel-Verlust, Überanpassung oder Test mit Trainingsdaten).</span><span class="sxs-lookup"><span data-stu-id="6b374-117">But exactly 1.00 indicates an issue (commonly: label/target leakage, over-fitting, or testing with training data).</span></span> <span data-ttu-id="6b374-118">Wenn die Testdaten unausgewogen sind (wobei die meisten Instanzen zu einer der Klassen gehören), das Dataset klein ist oder die Werte auf 0,00 oder 1,00 ansteigen, dann wird die Effektivität eines Klassifikators nicht wirklich erfasst, und Sie müssen zusätzliche Metriken überprüfen.</span><span class="sxs-lookup"><span data-stu-id="6b374-118">When the test data is unbalanced (where most of the instances belong to one of the classes), the dataset is small, or scores approach 0.00 or 1.00, then accuracy doesn't really capture the effectiveness of a classifier and you need to check additional metrics.</span></span> |
| <span data-ttu-id="6b374-119">**AUC**</span><span class="sxs-lookup"><span data-stu-id="6b374-119">**AUC**</span></span> |    <span data-ttu-id="6b374-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) oder *Area under the curve* (Fläche unter der Kurve) ist die Messung der Fläche unter der Kurve, die durch Abgleichen der True Positive-Rate mit der False Positive-Rate generiert wird.</span><span class="sxs-lookup"><span data-stu-id="6b374-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) or *Area under the curve* measures the area under the curve created by sweeping the true positive rate vs. the false positive rate.</span></span>  |   <span data-ttu-id="6b374-121">**Je näher der Wert an 1,00 liegt, desto besser**.</span><span class="sxs-lookup"><span data-stu-id="6b374-121">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="6b374-122">Der Wert muss größer als 0,50 sein, damit ein Modell akzeptabel ist.</span><span class="sxs-lookup"><span data-stu-id="6b374-122">It should be greater than 0.50 for a model to be acceptable.</span></span> <span data-ttu-id="6b374-123">Ein Modell mit einem AUC-Wert von 0,50 oder weniger ist wertlos.</span><span class="sxs-lookup"><span data-stu-id="6b374-123">A model with AUC of 0.50 or less is worthless.</span></span> |
| <span data-ttu-id="6b374-124">**aucPR**</span><span class="sxs-lookup"><span data-stu-id="6b374-124">**AUCPR**</span></span> | <span data-ttu-id="6b374-125">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) oder *Area under a Precision-Recall curve* (Fläche unter der Precision-Recall-Kurve): Ein nützliches Maß für den Erfolg der Vorhersage, wenn die Klassen unausgewogen sind (stark verzerrte Datasets).</span><span class="sxs-lookup"><span data-stu-id="6b374-125">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) or *Area under the curve of a Precision-Recall curve*: Useful measure of success of prediction when the classes are imbalanced (highly skewed datasets).</span></span> |  <span data-ttu-id="6b374-126">**Je näher der Wert an 1,00 liegt, desto besser**.</span><span class="sxs-lookup"><span data-stu-id="6b374-126">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="6b374-127">Hohe Werte nahe 1,00 zeigen, dass der Klassifikator sowohl genaue Ergebnisse liefert (hohe Präzision) als auch einen Großteil aller positiven Ergebnisse liefert (hohe Wiedererkennung).</span><span class="sxs-lookup"><span data-stu-id="6b374-127">High scores close to 1.00 show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).</span></span> |
| <span data-ttu-id="6b374-128">**F1-score**</span><span class="sxs-lookup"><span data-stu-id="6b374-128">**F1-score**</span></span> | <span data-ttu-id="6b374-129">[F1-score](https://en.wikipedia.org/wiki/F1_score) auch bezeichnet als *„balanced F-score“ oder F-Maß*.</span><span class="sxs-lookup"><span data-stu-id="6b374-129">[F1 score](https://en.wikipedia.org/wiki/F1_score) also known as *balanced F-score or F-measure*.</span></span> <span data-ttu-id="6b374-130">Dies ist das harmonische Mittel zwischen Präzision und Wiedererkennung.</span><span class="sxs-lookup"><span data-stu-id="6b374-130">It's the harmonic mean of the precision and recall.</span></span> <span data-ttu-id="6b374-131">F1 Score ist hilfreich, wenn das Verhältnis zwischen Präzision und Wiedererkennung ausgeglichen sein soll.</span><span class="sxs-lookup"><span data-stu-id="6b374-131">F1 Score is helpful when you want to seek a balance between Precision and Recall.</span></span>| <span data-ttu-id="6b374-132">**Je näher der Wert an 1,00 liegt, desto besser**.</span><span class="sxs-lookup"><span data-stu-id="6b374-132">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="6b374-133">Ein F1-Score erreicht seinen besten Wert bei 1,00 und den schlechtesten bei 0,00.</span><span class="sxs-lookup"><span data-stu-id="6b374-133">An F1 score reaches its best value at 1.00 and worst score at 0.00.</span></span> <span data-ttu-id="6b374-134">Daran erkennen Sie, wie präzise Ihr Klassifizierer ist.</span><span class="sxs-lookup"><span data-stu-id="6b374-134">It tells you how precise your classifier is.</span></span> |

<span data-ttu-id="6b374-135">Weitere Informationen zu binären Klassifizierungsmetriken finden Sie in den folgenden Artikeln:</span><span class="sxs-lookup"><span data-stu-id="6b374-135">For further details on binary classification metrics read the following articles:</span></span>

- <span data-ttu-id="6b374-136">[Accuracy, Precision, Recall or F1?](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9) (Genauigkeit, Präzision, Wiedererkennung oder F1?)</span><span class="sxs-lookup"><span data-stu-id="6b374-136">[Accuracy, Precision, Recall, or F1?](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)</span></span>
- <span data-ttu-id="6b374-137">[Binary Classification Metrics class](xref:Microsoft.ML.Data.BinaryClassificationMetrics) (Metrikklassen für die binäre Klassifizierung)</span><span class="sxs-lookup"><span data-stu-id="6b374-137">[Binary Classification Metrics class](xref:Microsoft.ML.Data.BinaryClassificationMetrics)</span></span>
- <span data-ttu-id="6b374-138">[The Relationship Between Precision-Recall and ROC Curves](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf) (Das Verhältnis zwischen Precision-Recall- und ROC-Kurven)</span><span class="sxs-lookup"><span data-stu-id="6b374-138">[The Relationship Between Precision-Recall and ROC Curves](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf)</span></span>

## <a name="evaluation-metrics-for-multi-class-classification"></a><span data-ttu-id="6b374-139">Auswertungsmetriken für mehrklassige Klassifizierung</span><span class="sxs-lookup"><span data-stu-id="6b374-139">Evaluation metrics for Multi-class Classification</span></span>

| <span data-ttu-id="6b374-140">Metriken</span><span class="sxs-lookup"><span data-stu-id="6b374-140">Metrics</span></span>   |      <span data-ttu-id="6b374-141">BESCHREIBUNG</span><span class="sxs-lookup"><span data-stu-id="6b374-141">Description</span></span>      |  <span data-ttu-id="6b374-142">Suchen nach</span><span class="sxs-lookup"><span data-stu-id="6b374-142">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="6b374-143">**Micro-Accuracy**</span><span class="sxs-lookup"><span data-stu-id="6b374-143">**Micro-Accuracy**</span></span> |  <span data-ttu-id="6b374-144">Die [durchschnittliche Mikrogenauigkeit](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) aggregiert die Beiträge aller Klassen zur Berechnung der durchschnittlichen Metrik.</span><span class="sxs-lookup"><span data-stu-id="6b374-144">[Micro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) aggregates the contributions of all classes to compute the average metric.</span></span> <span data-ttu-id="6b374-145">Es ist der Anteil der korrekt vorhergesagten Instanzen.</span><span class="sxs-lookup"><span data-stu-id="6b374-145">It is the fraction of instances predicted correctly.</span></span> <span data-ttu-id="6b374-146">Der Mikrodurchschnitt berücksichtigt nicht die Klassenzugehörigkeit.</span><span class="sxs-lookup"><span data-stu-id="6b374-146">The micro-average does not take class membership into account.</span></span> <span data-ttu-id="6b374-147">Jedes Beispiel/Klasse-Paar trägt grundsätzlich zu gleichen Teilen zur Genauigkeitsmetrik bei.</span><span class="sxs-lookup"><span data-stu-id="6b374-147">Basically, every sample-class pair contributes equally to the accuracy metric.</span></span> | <span data-ttu-id="6b374-148">**Je näher der Wert an 1,00 liegt, desto besser**.</span><span class="sxs-lookup"><span data-stu-id="6b374-148">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="6b374-149">In einer Aufgabe für die Multiklassenklassifizierung ist die Mikrogenauigkeit der Makrogenauigkeit vorzuziehen, wenn Sie vermuten, dass es ein Klassenungleichgewicht geben könnte (d.h.</span><span class="sxs-lookup"><span data-stu-id="6b374-149">In a multi-class classification task, micro-accuracy is preferable over macro-accuracy if you suspect there might be class imbalance (i.e</span></span> <span data-ttu-id="6b374-150">Sie haben viel mehr Beispiele für eine Klasse als für andere Klassen).</span><span class="sxs-lookup"><span data-stu-id="6b374-150">you may have many more examples of one class than of other classes).</span></span>|
| <span data-ttu-id="6b374-151">**Macro-Accuracy**</span><span class="sxs-lookup"><span data-stu-id="6b374-151">**Macro-Accuracy**</span></span> | <span data-ttu-id="6b374-152">Die [durchschnittliche Makrogenauigkeit](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) ist die durchschnittliche Genauigkeit auf Klassenebene.</span><span class="sxs-lookup"><span data-stu-id="6b374-152">[Macro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) is the average accuracy at the class level.</span></span> <span data-ttu-id="6b374-153">Die Genauigkeit für jede Klasse wird berechnet, und die Makrogenauigkeit ist der Durchschnitt dieser Genauigkeiten.</span><span class="sxs-lookup"><span data-stu-id="6b374-153">The accuracy for each class is computed and the macro-accuracy is the average of these accuracies.</span></span> <span data-ttu-id="6b374-154">Grundsätzlich trägt jede Klasse zu gleichen Teilen zur Genauigkeitsmetrik bei.</span><span class="sxs-lookup"><span data-stu-id="6b374-154">Basically, every class contributes equally to the accuracy metric.</span></span> <span data-ttu-id="6b374-155">Minderheitsklassen werden gleich wie größere Klassen gewichtet.</span><span class="sxs-lookup"><span data-stu-id="6b374-155">Minority classes are given equal weight as the larger classes.</span></span> <span data-ttu-id="6b374-156">Die Metrik gibt jeder Klasse die gleiche Gewichtung, unabhängig davon, wie viele Instanzen aus dieser Klasse das Dataset enthält.</span><span class="sxs-lookup"><span data-stu-id="6b374-156">The macro-average metric gives the same weight to each class, no matter how many instances from that class the dataset contains.</span></span> |  <span data-ttu-id="6b374-157">**Je näher der Wert an 1,00 liegt, desto besser**.</span><span class="sxs-lookup"><span data-stu-id="6b374-157">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="6b374-158">Sie berechnet die Metrik unabhängig für jede Klasse und ermittelt dann den Durchschnitt (daher werden alle Klassen gleich behandelt).</span><span class="sxs-lookup"><span data-stu-id="6b374-158">It computes the metric independently for each class and then takes the average (hence treating all classes equally)</span></span> |
| <span data-ttu-id="6b374-159">**Log-loss**</span><span class="sxs-lookup"><span data-stu-id="6b374-159">**Log-loss**</span></span>| <span data-ttu-id="6b374-160">Der logarithmische Verlust misst die Leistung eines Klassifizierungsmodells, wobei die Vorhersageeingabe ein Wahrscheinlichkeitswert zwischen 0,00 und 1,00 ist.</span><span class="sxs-lookup"><span data-stu-id="6b374-160">Logarithmic loss measures the performance of a classification model where the prediction input is a probability value between 0.00 and 1.00.</span></span> <span data-ttu-id="6b374-161">Der Wert steigt, wenn die vorhergesagte Wahrscheinlichkeit von der tatsächlichen Bezeichnung abweicht.</span><span class="sxs-lookup"><span data-stu-id="6b374-161">Log-loss increases as the predicted probability diverges from the actual label.</span></span> | <span data-ttu-id="6b374-162">**Je näher der Wert an 0,00 liegt, desto besser**.</span><span class="sxs-lookup"><span data-stu-id="6b374-162">**The closer to 0.00, the better**.</span></span> <span data-ttu-id="6b374-163">Bei einem perfekten Modell liegt der Wert bei 0,00.</span><span class="sxs-lookup"><span data-stu-id="6b374-163">A perfect model would have a log-loss of 0.00.</span></span> <span data-ttu-id="6b374-164">Ziel unserer Machine Learning-Modelle ist es, diesen Wert zu minimieren.</span><span class="sxs-lookup"><span data-stu-id="6b374-164">The goal of our machine learning models is to minimize this value.</span></span>|
| <span data-ttu-id="6b374-165">**Log-Loss Reduction**</span><span class="sxs-lookup"><span data-stu-id="6b374-165">**Log-Loss Reduction**</span></span> | <span data-ttu-id="6b374-166">Die [logarithmische Verlustreduzierung](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) kann als Vorteil des Klassifizierers gegenüber einer Zufallsvorhersage interpretiert werden.</span><span class="sxs-lookup"><span data-stu-id="6b374-166">[Logarithmic loss reduction](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) can be interpreted as the advantage of the classifier over a random prediction.</span></span>| <span data-ttu-id="6b374-167">**Liegt zwischen [-inf, 1.00], wobei „1.00“ perfekte Vorhersagen und „0.00“ durchschnittliche Vorhersagen bedeutet.**</span><span class="sxs-lookup"><span data-stu-id="6b374-167">**Ranges from -inf and 1.00, where 1.00 is perfect predictions and 0.00 indicates mean predictions**.</span></span> <span data-ttu-id="6b374-168">Wenn der Wert beispielsweise 0,20 beträgt, kann er als „die Wahrscheinlichkeit einer korrekten Vorhersage ist 20 % besser als eine zufällige Schätzung“ interpretiert werden.</span><span class="sxs-lookup"><span data-stu-id="6b374-168">For example, if the value equals 0.20, it can be interpreted as "the probability of a correct prediction is 20% better than random guessing"</span></span>|

<span data-ttu-id="6b374-169">Die Mikrogenauigkeit ist im Allgemeinen besser auf die Geschäftsanforderungen der ML-Vorhersagen ausgerichtet.</span><span class="sxs-lookup"><span data-stu-id="6b374-169">Micro-accuracy is generally better aligned with the business needs of ML predictions.</span></span> <span data-ttu-id="6b374-170">Wenn Sie eine einzelne Metrik für die Auswahl der Qualität einer Aufgabe für die Multiklassenklassifizierung auswählen, sollte dies in der Regel die Mikrogenauigkeit sein.</span><span class="sxs-lookup"><span data-stu-id="6b374-170">If you want to select a single metric for choosing the quality of a multiclass classification task, it should usually be micro-accuracy.</span></span>

<span data-ttu-id="6b374-171">Beispiel für eine Aufgabe zur Klassifizierung von Supporttickets: (ordnet eingehende Tickets den Support-Teams zu)</span><span class="sxs-lookup"><span data-stu-id="6b374-171">Example, for a support ticket classification task: (maps incoming tickets to support teams)</span></span>

- <span data-ttu-id="6b374-172">Mikrogenauigkeit – wie oft wird ein eingehendes Ticket dem richtigen Team zugeordnet?</span><span class="sxs-lookup"><span data-stu-id="6b374-172">Micro-accuracy -- how often does an incoming ticket get classified to the right team?</span></span>
- <span data-ttu-id="6b374-173">Makrogenauigkeit für dein durchschnittliches Team – wie oft ist ein eingehendes Ticket das richtige Ticket für das Team?</span><span class="sxs-lookup"><span data-stu-id="6b374-173">Macro-accuracy -- for an average team, how often is an incoming ticket correct for their team?</span></span>

<span data-ttu-id="6b374-174">Die Makrogenauigkeit gewichtet in diesem Beispiel kleine Teams zu hoch: Ein kleines Team, das nur 10 Tickets pro Jahr erhält, zählt ebenso viel wie ein großes Team mit 10.000 Tickets pro Jahr.</span><span class="sxs-lookup"><span data-stu-id="6b374-174">Macro-accuracy overweights small teams in this example; a small team that gets only 10 tickets per year counts as much as a large team with 10k tickets per year.</span></span> <span data-ttu-id="6b374-175">Die Mikrogenauigkeit korreliert in diesem Fall besser mit der Geschäftsanforderung: „Wie viel Zeit/Geld kann das Unternehmen durch die Automatisierung meines Prozesses für die Ticketweiterleitung sparen“.</span><span class="sxs-lookup"><span data-stu-id="6b374-175">Micro-accuracy in this case correlates better with the business need of, "how much time/money can the company save by automating my ticket routing process".</span></span>

<span data-ttu-id="6b374-176">Weitere Informationen zu Metriken für die Multiklassenklassifizierung finden Sie in den folgenden Artikeln:</span><span class="sxs-lookup"><span data-stu-id="6b374-176">For further details on multi-class classification metrics read the following articles:</span></span>

- <span data-ttu-id="6b374-177">[Micro- and Macro-average of Precision, Recall and F-Score](https://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html) (Mikro- und Makrodurchschnitt von Präzision, Wiedererkennung und F-Score)</span><span class="sxs-lookup"><span data-stu-id="6b374-177">[Micro- and Macro-average of Precision, Recall, and F-Score](https://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html)</span></span>
- <span data-ttu-id="6b374-178">[Multiclass Classification with Imbalanced Dataset](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a) (Multiklassenklassifizierung mit unausgeglichenen Datasets)</span><span class="sxs-lookup"><span data-stu-id="6b374-178">[Multiclass Classification with Imbalanced Dataset](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a)</span></span>

## <a name="evaluation-metrics-for-regression-and-recommendation"></a><span data-ttu-id="6b374-179">Auswertungsmetriken für Regression und Empfehlung</span><span class="sxs-lookup"><span data-stu-id="6b374-179">Evaluation metrics for Regression and Recommendation</span></span>

<span data-ttu-id="6b374-180">Sowohl die Regressions- als auch die Empfehlungsaufgabe prognostizieren eine Zahl.</span><span class="sxs-lookup"><span data-stu-id="6b374-180">Both the regression and recommendation tasks predict a number.</span></span> <span data-ttu-id="6b374-181">Im Fall von Regression kann die Zahl jede Ausgabeeigenschaft sein, die von den Eingabeeigenschaften beeinflusst wird.</span><span class="sxs-lookup"><span data-stu-id="6b374-181">In the case of regression, the number can be any output property that is influenced by the input properties.</span></span> <span data-ttu-id="6b374-182">Bei der Empfehlung ist die Zahl in der Regel ein Bewertungswert (z. B. zwischen 1 und 5) oder eine Ja/Nein-Empfehlung (dargestellt durch 1 bzw. 0).</span><span class="sxs-lookup"><span data-stu-id="6b374-182">For recommendation, the number is usually a rating value (between 1 and 5 for example), or a yes/no recommendation (represented by 1 and 0 respectively).</span></span>

| <span data-ttu-id="6b374-183">Metrik</span><span class="sxs-lookup"><span data-stu-id="6b374-183">Metric</span></span>   |      <span data-ttu-id="6b374-184">BESCHREIBUNG</span><span class="sxs-lookup"><span data-stu-id="6b374-184">Description</span></span>      |  <span data-ttu-id="6b374-185">Suchen nach</span><span class="sxs-lookup"><span data-stu-id="6b374-185">Look for</span></span> |
|----------|-----------------------|-----------|
| <span data-ttu-id="6b374-186">**R-squared**</span><span class="sxs-lookup"><span data-stu-id="6b374-186">**R-Squared**</span></span> |  <span data-ttu-id="6b374-187">[R-squared (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination) oder *Bestimmtheitsmaß* stellt die Vorhersageleistung des Modells als Wert zwischen -inf und 1,00 dar.</span><span class="sxs-lookup"><span data-stu-id="6b374-187">[R-squared (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), or *Coefficient of determination* represents the predictive power of the model as a value between -inf and 1.00.</span></span> <span data-ttu-id="6b374-188">1,00 bedeutet, dass das Modell perfekt geeignet ist. Die Eignung kann aber auch willkürlich schlecht sein, sodass die Werte negativ sein können.</span><span class="sxs-lookup"><span data-stu-id="6b374-188">1.00 means there is a perfect fit, and the fit can be arbitrarily poor so the scores can be negative.</span></span> <span data-ttu-id="6b374-189">Ein Score von 0,00 bedeutet, dass das Modell den erwarteten Wert für die Bezeichnung schätzt.</span><span class="sxs-lookup"><span data-stu-id="6b374-189">A score of 0.00 means the model is guessing the expected value for the label.</span></span> <span data-ttu-id="6b374-190">R2 misst, wie nah die tatsächlichen Testdatenwerte an den vorhergesagten Werten liegen.</span><span class="sxs-lookup"><span data-stu-id="6b374-190">R2 measures how close the actual test data values are to the predicted values.</span></span> | <span data-ttu-id="6b374-191">**Je näher der Wert an 1,00 liegt, desto besser ist die Qualität des Modells**.</span><span class="sxs-lookup"><span data-stu-id="6b374-191">**The closer to 1.00, the better quality**.</span></span> <span data-ttu-id="6b374-192">Manchmal können jedoch niedrige R-squared-Werte (z.B. 0,50) ganz normal oder gut genug für Ihr Szenario sein, und hohe R-squared-Werte sind nicht immer gut und möglicherweise verdächtig.</span><span class="sxs-lookup"><span data-stu-id="6b374-192">However, sometimes low R-squared values (such as 0.50) can be entirely normal or good enough for your scenario and high R-squared values are not always good and be suspicious.</span></span> |
| <span data-ttu-id="6b374-193">**Absolute-loss**</span><span class="sxs-lookup"><span data-stu-id="6b374-193">**Absolute-loss**</span></span> |  <span data-ttu-id="6b374-194">[Absolute-loss](https://en.wikipedia.org/wiki/Mean_absolute_error) oder *Mittlerer absoluter Fehler (MAE)* misst, wie nah die Vorhersagen an den tatsächlichen Ergebnissen liegen.</span><span class="sxs-lookup"><span data-stu-id="6b374-194">[Absolute-loss](https://en.wikipedia.org/wiki/Mean_absolute_error) or *Mean absolute error (MAE)* measures how close the predictions are to the actual outcomes.</span></span> <span data-ttu-id="6b374-195">Damit wird der Durchschnitt aller Modellfehler angegeben, wobei ein Modellfehler die Differenz zwischen dem vorhergesagten Wert für die Bezeichnung und dem korrekten Wert für die Bezeichnung ist.</span><span class="sxs-lookup"><span data-stu-id="6b374-195">It is the average of all the model errors, where model error is the absolute distance between the predicted label value and the correct label value.</span></span> <span data-ttu-id="6b374-196">Dieser Vorhersagefehler wird für jeden Datensatz des Testdatasets berechnet.</span><span class="sxs-lookup"><span data-stu-id="6b374-196">This prediction error is calculated for each record of the test data set.</span></span> <span data-ttu-id="6b374-197">Abschließend wird der Mittelwert für alle erfassten absoluten Fehler berechnet.</span><span class="sxs-lookup"><span data-stu-id="6b374-197">Finally, the mean value is calculated for all recorded absolute errors.</span></span>| <span data-ttu-id="6b374-198">**Je näher der Wert an 0,00 liegt, desto besser ist die Qualität des Modells**.</span><span class="sxs-lookup"><span data-stu-id="6b374-198">**The closer to 0.00, the better quality.**</span></span> <span data-ttu-id="6b374-199">Der mittlere absolute Fehler verwendet die gleiche Staffelung wie die zu messenden Daten (ist nicht für einen bestimmten Bereich normalisiert).</span><span class="sxs-lookup"><span data-stu-id="6b374-199">The mean absolute error uses the same scale as the data being measured (is not normalized to specific range).</span></span> <span data-ttu-id="6b374-200">„Absolute-loss“, „Squared-loss“ und „RMS-loss“ können nur zum Vergleich von Modellen für dasselbe Dataset oder Datasets mit einer ähnlichen Bezeichnung-Wert-Verteilung verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="6b374-200">Absolute-loss, Squared-loss, and RMS-loss can only be used to make comparisons between models for the same dataset or dataset with a similar label value distribution.</span></span> |
| <span data-ttu-id="6b374-201">**Squared-loss**</span><span class="sxs-lookup"><span data-stu-id="6b374-201">**Squared-loss**</span></span> |  <span data-ttu-id="6b374-202">[Squared-loss](https://en.wikipedia.org/wiki/Mean_squared_error) oder *Mittlerer quadratischer Fehler (Mean Squared Error, MSE)*, auch *Mittlere quadratische Abweichung (Mean Squared Deviation, MSD)* genannt, gibt an, wie nahe eine Regressionslinie an einer Reihe von Testdatenwerten liegt, indem die Abstände der Punkte zur Regressionslinie (diese Abstände sind die Fehler E) ermittelt und ins Quadrat erhoben werden.</span><span class="sxs-lookup"><span data-stu-id="6b374-202">[Squared-loss](https://en.wikipedia.org/wiki/Mean_squared_error) or *Mean Squared Error (MSE)*, also called *Mean Squared Deviation (MSD)*, tells you how close a regression line is to a set of test data values by taking the distances from the points to the regression line (these distances are the errors E) and squaring them.</span></span> <span data-ttu-id="6b374-203">Durch das Quadrieren wird größeren Unterschieden eine höhere Gewichtung zugewiesen.</span><span class="sxs-lookup"><span data-stu-id="6b374-203">The squaring gives more weight to larger differences.</span></span> | <span data-ttu-id="6b374-204">Der Wert ist immer nicht negativ, und **Werte, die näher an 0,00 liegen, sind besser**.</span><span class="sxs-lookup"><span data-stu-id="6b374-204">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="6b374-205">In Abhängigkeit von Ihren Daten kann es unmöglich sein, für den mittleren quadratischen Fehler einen sehr kleinen Wert zu erhalten.</span><span class="sxs-lookup"><span data-stu-id="6b374-205">Depending on your data, it may be impossible to get a very small value for the mean squared error.</span></span>|
| <span data-ttu-id="6b374-206">**RMS-loss**</span><span class="sxs-lookup"><span data-stu-id="6b374-206">**RMS-loss**</span></span> |  <span data-ttu-id="6b374-207">[RMS-loss](https://en.wikipedia.org/wiki/Root-mean-square_deviation) oder *Wurzel aus dem mittleren quadratischen Fehler (Root Mean Squared Error, RMSE)* (auch als *Wurzel aus der mittleren quadratischen Abweichung [Root Mean Square Deviation, RMSD*]), misst die Differenz zwischen den von einem Modell vorhergesagten Werten und den beobachteten Werten aus der zu modellierenden Umgebung.</span><span class="sxs-lookup"><span data-stu-id="6b374-207">[RMS-loss](https://en.wikipedia.org/wiki/Root-mean-square_deviation) or *Root Mean Squared Error (RMSE)* (also called *Root Mean Square Deviation, RMSD*), measures the difference between values predicted by a model and the values observed from the environment that is being modeled.</span></span> <span data-ttu-id="6b374-208">„RMS-loss“ ist die Quadratwurzel von „Squared-loss“ und verwendet, ähnlich wie „Absolute-loss“ dieselben Einheiten wie die Bezeichnung, weist jedoch größeren Unterschieden mehr Gewichtung zu.</span><span class="sxs-lookup"><span data-stu-id="6b374-208">RMS-loss is the square root of Squared-loss and has the same units as the label, similar to the absolute-loss though giving more weight to larger differences.</span></span> <span data-ttu-id="6b374-209">Die Wurzel aus dem mittleren quadratischen Fehler wird häufig in der Klimatologie, für Vorhersagen und Regressionsanalyse verwendet, um experimentelle Ergebnisse zu überprüfen.</span><span class="sxs-lookup"><span data-stu-id="6b374-209">Root mean square error is commonly used in climatology, forecasting, and regression analysis to verify experimental results.</span></span> | <span data-ttu-id="6b374-210">Der Wert ist immer nicht negativ, und **Werte, die näher an 0,00 liegen, sind besser**.</span><span class="sxs-lookup"><span data-stu-id="6b374-210">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="6b374-211">RMSD ist ein Maß für die Genauigkeit, um Vorhersagefehler verschiedener Modelle für ein bestimmtes Dataset zu vergleichen und nicht für verschiedene Datasets, da der Wert staffelungsabhängig ist.</span><span class="sxs-lookup"><span data-stu-id="6b374-211">RMSD is a measure of accuracy, to compare forecasting errors of different models for a particular dataset and not between datasets, as it is scale-dependent.</span></span>|

<span data-ttu-id="6b374-212">Weitere Informationen zu Regressionsmetriken finden Sie in den folgenden Artikeln:</span><span class="sxs-lookup"><span data-stu-id="6b374-212">For further details on regression metrics, read the following articles:</span></span>

- <span data-ttu-id="6b374-213">[Regression Analysis: How Do I Interpret R-squared and Assess the Goodness-of-Fit?](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit) (Regressionsanalyse: Interpretieren von „R-squared“ und Bewerten der Anpassungsgüte)</span><span class="sxs-lookup"><span data-stu-id="6b374-213">[Regression Analysis: How Do I Interpret R-squared and Assess the Goodness-of-Fit?](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)</span></span>
- <span data-ttu-id="6b374-214">[How To Interpret R-squared in Regression Analysis](https://statisticsbyjim.com/regression/interpret-r-squared-regression) (Interpretieren von „R-squared“ in der Regressionsanalyse)</span><span class="sxs-lookup"><span data-stu-id="6b374-214">[How To Interpret R-squared in Regression Analysis](https://statisticsbyjim.com/regression/interpret-r-squared-regression)</span></span>
- <span data-ttu-id="6b374-215">[R-Squared Definition](https://www.investopedia.com/terms/r/r-squared.asp) (R-Squared-Definition)</span><span class="sxs-lookup"><span data-stu-id="6b374-215">[R-Squared Definition](https://www.investopedia.com/terms/r/r-squared.asp)</span></span>
- <span data-ttu-id="6b374-216">[Mean Squared Error Definition](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/) (Definition des mittleren quadratischen Fehlers)</span><span class="sxs-lookup"><span data-stu-id="6b374-216">[Mean Squared Error Definition](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/)</span></span>
- <span data-ttu-id="6b374-217">[What are Mean Squared Error and Root Mean Squared Error?](https://www.vernier.com/til/1014/) (Was sind der mittlere quadratische Fehler und die Wurzel aus dem mittleren quadratischen Fehler?)</span><span class="sxs-lookup"><span data-stu-id="6b374-217">[What are Mean Squared Error and Root Mean Squared Error?](https://www.vernier.com/til/1014/)</span></span>

## <a name="evaluation-metrics-for-clustering"></a><span data-ttu-id="6b374-218">Auswertungsmetriken für Clustering</span><span class="sxs-lookup"><span data-stu-id="6b374-218">Evaluation metrics for Clustering</span></span>

| <span data-ttu-id="6b374-219">Metrik</span><span class="sxs-lookup"><span data-stu-id="6b374-219">Metric</span></span>   |      <span data-ttu-id="6b374-220">BESCHREIBUNG</span><span class="sxs-lookup"><span data-stu-id="6b374-220">Description</span></span>      |  <span data-ttu-id="6b374-221">Suchen nach</span><span class="sxs-lookup"><span data-stu-id="6b374-221">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="6b374-222">**Durchschnittlicher Abstand**</span><span class="sxs-lookup"><span data-stu-id="6b374-222">**Average Distance**</span></span>|<span data-ttu-id="6b374-223">Der Durchschnitt des Abstands zwischen Datenpunkten und der Mitte des zugewiesenen Clusters.</span><span class="sxs-lookup"><span data-stu-id="6b374-223">Average of the distance between data points and the center of their assigned cluster.</span></span> <span data-ttu-id="6b374-224">Der mittlere Abstand ist ein Maß für die Nähe der Datenpunkte zu den Clusterschwerpunkten.</span><span class="sxs-lookup"><span data-stu-id="6b374-224">The average distance is a measure of proximity of the data points to cluster centroids.</span></span> <span data-ttu-id="6b374-225">Es ist ein Maß dafür, wie „dicht“ der Cluster ist.</span><span class="sxs-lookup"><span data-stu-id="6b374-225">It's a measure of how 'tight' the cluster is.</span></span>|<span data-ttu-id="6b374-226">Werte, die näher an **0** liegen, sind besser.</span><span class="sxs-lookup"><span data-stu-id="6b374-226">Values closer to **0** are better.</span></span> <span data-ttu-id="6b374-227">Je näher an Null der mittlere Abstand liegt, desto stärker sind die Daten gruppiert.</span><span class="sxs-lookup"><span data-stu-id="6b374-227">The closer to zero the average distance is, the more clustered the data is.</span></span> <span data-ttu-id="6b374-228">Beachten Sie jedoch, dass diese Metrik abnimmt, wenn die Anzahl der Cluster erhöht wird, und im Extremfall (wenn jeder einzelne Datenpunkt einen eigenen Cluster darstellt) gleich Null ist.</span><span class="sxs-lookup"><span data-stu-id="6b374-228">Note though, that this metric will decrease if the number of clusters is increased, and in the extreme case (where each distinct data point is its own cluster) it will be equal to zero.</span></span>
|<span data-ttu-id="6b374-229">**Davies-Bouldin-Index**</span><span class="sxs-lookup"><span data-stu-id="6b374-229">**Davies Bouldin Index**</span></span>|<span data-ttu-id="6b374-230">Das durchschnittliche Verhältnis der Abstände innerhalb der Cluster zu den Abständen zwischen den Clustern.</span><span class="sxs-lookup"><span data-stu-id="6b374-230">The average ratio of within-cluster distances to between-cluster distances.</span></span> <span data-ttu-id="6b374-231">Je dichter der Cluster und je weiter die Cluster voneinander entfernt sind, desto niedriger ist dieser Wert.</span><span class="sxs-lookup"><span data-stu-id="6b374-231">The tighter the cluster, and the further apart the clusters are, the lower this value is.</span></span>|<span data-ttu-id="6b374-232">Werte, die näher an **0** liegen, sind besser.</span><span class="sxs-lookup"><span data-stu-id="6b374-232">Values closer to **0** are better.</span></span> <span data-ttu-id="6b374-233">Cluster, die weiter auseinander liegen und weniger verstreut sind, führen zu einer besseren Bewertung.</span><span class="sxs-lookup"><span data-stu-id="6b374-233">Clusters that are farther apart and less dispersed will result in a better score.</span></span>|
|<span data-ttu-id="6b374-234">**Normalized Mutual Information (normalisierte Transinformation)**</span><span class="sxs-lookup"><span data-stu-id="6b374-234">**Normalized Mutual Information**</span></span>|<span data-ttu-id="6b374-235">Kann verwendet werden, wenn die Trainingsdaten, mit denen das Clusteringmodell trainiert wird, auch mit Ground Truth-Bezeichnungen versehen sind (d. h. überwachtes Clustering).</span><span class="sxs-lookup"><span data-stu-id="6b374-235">Can be used when the training data used to train the clustering model also comes with ground truth labels (that is, supervised clustering).</span></span> <span data-ttu-id="6b374-236">Die Metrik „Normalized Mutual Information“ misst, ob ähnliche Datenpunkte demselben Cluster zugewiesen werden und unterschiedliche Datenpunkte verschiedenen Clustern zugewiesen werden.</span><span class="sxs-lookup"><span data-stu-id="6b374-236">The Normalized Mutual Information metric measures whether similar data points get assigned to the same cluster and disparate data points get assigned to different clusters.</span></span> <span data-ttu-id="6b374-237">„Normalized Mutual Informationen“ ist ein Wert zwischen 0 und 1.</span><span class="sxs-lookup"><span data-stu-id="6b374-237">Normalized mutual information is a value between 0 and 1</span></span>|<span data-ttu-id="6b374-238">Werte, die näher an **1** liegen, sind besser.</span><span class="sxs-lookup"><span data-stu-id="6b374-238">Values closer to **1** are better</span></span>|

## <a name="evaluation-metrics-for-ranking"></a><span data-ttu-id="6b374-239">Auswertungsmetriken für Rangfolge</span><span class="sxs-lookup"><span data-stu-id="6b374-239">Evaluation metrics for Ranking</span></span>

| <span data-ttu-id="6b374-240">Metrik</span><span class="sxs-lookup"><span data-stu-id="6b374-240">Metric</span></span>   |      <span data-ttu-id="6b374-241">BESCHREIBUNG</span><span class="sxs-lookup"><span data-stu-id="6b374-241">Description</span></span>      |  <span data-ttu-id="6b374-242">Suchen nach</span><span class="sxs-lookup"><span data-stu-id="6b374-242">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="6b374-243">**Discounted Cumulative Gains (diskontierte kumulative Zuwächse)**</span><span class="sxs-lookup"><span data-stu-id="6b374-243">**Discounted Cumulative Gains**</span></span>|<span data-ttu-id="6b374-244">Discounted Cumulative Gain (DCG) ist ein Maß für Rangfolgequalität.</span><span class="sxs-lookup"><span data-stu-id="6b374-244">Discounted cumulative gain (DCG) is a measure of ranking quality.</span></span> <span data-ttu-id="6b374-245">Diese Metrik wird von zwei Annahmen abgeleitet.</span><span class="sxs-lookup"><span data-stu-id="6b374-245">It is derived from two assumptions.</span></span> <span data-ttu-id="6b374-246">Annahme 1: Besonders relevante Elemente sind nützlicher, wenn Sie höher in der Rangfolge erscheinen.</span><span class="sxs-lookup"><span data-stu-id="6b374-246">One: Highly relevant items are more useful when appearing higher in ranking order.</span></span> <span data-ttu-id="6b374-247">Annahme 2: Nützlichkeit folgt Relevanz: Je höher die Relevanz, desto nützlicher ist ein Element.</span><span class="sxs-lookup"><span data-stu-id="6b374-247">Two: Usefulness tracks relevance that is, the higher the relevance, the more useful an item.</span></span> <span data-ttu-id="6b374-248">DCG wird für eine bestimmte Position in der Rangfolge berechnet.</span><span class="sxs-lookup"><span data-stu-id="6b374-248">Discounted cumulative gain is calculated for a particular position in the ranking order.</span></span> <span data-ttu-id="6b374-249">Die Metrik summiert die Relevanzbewertung, dividiert durch den Logarithmus des Rangfolgeindexes bis zur gewünschten Position.</span><span class="sxs-lookup"><span data-stu-id="6b374-249">It sums the relevance grading divided by the logarithm of the ranking index up to the position of interest.</span></span> <span data-ttu-id="6b374-250">Die Berechnung erfolgt mit $\sum_{i=0}^{p} \frac {rel_i} {\log_{e}{i+1}}$. Relevanzgrade werden einem Rangfolge-Trainingsalgorithmus als Ground Truth-Bezeichnungen zur Verfügung gestellt.</span><span class="sxs-lookup"><span data-stu-id="6b374-250">It is calculated using $\sum_{i=0}^{p} \frac {rel_i} {\log_{e}{i+1}}$ Relevance gradings are provided to a ranking training algorithm as ground truth labels.</span></span> <span data-ttu-id="6b374-251">Ein DCG-Wert wird für jede Position in der Rangfolgetabelle bereitgestellt, daher der Name „Discounted Cumulative **Gains**“.</span><span class="sxs-lookup"><span data-stu-id="6b374-251">One DCG value is provided for each position in the ranking table, hence the name Discounted Cumulative **Gains**.</span></span> |<span data-ttu-id="6b374-252">**Höhere Werte sind besser**</span><span class="sxs-lookup"><span data-stu-id="6b374-252">**Higher values are better**</span></span>|
|<span data-ttu-id="6b374-253">**Normalized Discounted Cumulative Gains (normalisierte diskontierte kumulative Zuwächse)**</span><span class="sxs-lookup"><span data-stu-id="6b374-253">**Normalized Discounted Cumulative Gains**</span></span>|<span data-ttu-id="6b374-254">Durch die Normalisierung von DCG kann die Metrik für Rangfolgelisten mit unterschiedlicher Länge verglichen werden.</span><span class="sxs-lookup"><span data-stu-id="6b374-254">Normalizing DCG allows the metric to be compared for ranking lists of different lengths</span></span>|<span data-ttu-id="6b374-255">**Werte, die näher an 1 liegen, sind besser**</span><span class="sxs-lookup"><span data-stu-id="6b374-255">**Values closer to 1 are better**</span></span>|

## <a name="evaluation-metrics-for-anomaly-detection"></a><span data-ttu-id="6b374-256">Auswertungsmetriken für Anomalieerkennung</span><span class="sxs-lookup"><span data-stu-id="6b374-256">Evaluation metrics for Anomaly Detection</span></span>

| <span data-ttu-id="6b374-257">Metrik</span><span class="sxs-lookup"><span data-stu-id="6b374-257">Metric</span></span>   |      <span data-ttu-id="6b374-258">BESCHREIBUNG</span><span class="sxs-lookup"><span data-stu-id="6b374-258">Description</span></span>      |  <span data-ttu-id="6b374-259">Suchen nach</span><span class="sxs-lookup"><span data-stu-id="6b374-259">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="6b374-260">**Area Under ROC Curve (Bereich unter der ROC-Kurve)**</span><span class="sxs-lookup"><span data-stu-id="6b374-260">**Area Under ROC Curve**</span></span>|<span data-ttu-id="6b374-261">Der Bereich unter der Empfängeroperatorkurve misst, wie gut das Modell anormale und normale Datenpunkte trennt.</span><span class="sxs-lookup"><span data-stu-id="6b374-261">Area under the receiver operator curve measures how well the model separates anomalous and usual data points.</span></span>|<span data-ttu-id="6b374-262">**Werte, die näher an 1 liegen, sind besser**.</span><span class="sxs-lookup"><span data-stu-id="6b374-262">**Values closer to 1 are better**.</span></span> <span data-ttu-id="6b374-263">Nur Werte größer als 0,5 veranschaulichen die Effektivität des Modells.</span><span class="sxs-lookup"><span data-stu-id="6b374-263">Only values greater than 0.5 demonstrate effectiveness of the model.</span></span> <span data-ttu-id="6b374-264">Werte von 0,5 oder niedriger weisen darauf hin, dass das Modell nicht besser ist als das zufällige Zuordnen der Eingaben zu anormalen und normalen Kategorien.</span><span class="sxs-lookup"><span data-stu-id="6b374-264">Values of 0.5 or below indicate that the model is no better than randomly allocating the inputs to anomalous and usual categories</span></span>|
|<span data-ttu-id="6b374-265">**Detection Rate At False Positive Count (Erkennungsrate bei falsch positiver Anzahl)**</span><span class="sxs-lookup"><span data-stu-id="6b374-265">**Detection Rate At False Positive Count**</span></span>|<span data-ttu-id="6b374-266">Die Erkennungsrate bei falsch positiver Anzahl ist das Verhältnis zwischen der Anzahl der richtig identifizierten Anomalien und der Gesamtzahl der Anomalien in einem Testsatz, indiziert durch die einzelnen falsch positiven Elemente.</span><span class="sxs-lookup"><span data-stu-id="6b374-266">Detection rate at false positive count is the ratio of the number of correctly identified anomalies to the total number of anomalies in a test set, indexed by each false positive.</span></span> <span data-ttu-id="6b374-267">Das heißt, es gibt einen Wert für die Erkennungsrate bei falscher positiver Anzahl für jedes falsch positive Element.</span><span class="sxs-lookup"><span data-stu-id="6b374-267">That is, there is a value for detection rate at false positive count for each false positive item.</span></span>|<span data-ttu-id="6b374-268">**Werte, die näher an 1 liegen, sind besser**.</span><span class="sxs-lookup"><span data-stu-id="6b374-268">**Values closer to 1 are better**.</span></span> <span data-ttu-id="6b374-269">Wenn keine falsch positiven Elemente vorliegen, ist dieser Wert 1.</span><span class="sxs-lookup"><span data-stu-id="6b374-269">If there are no false positives, then this value is 1</span></span>|
